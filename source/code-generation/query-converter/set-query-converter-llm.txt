.. _rm-query-converter-set-llm:

============================================
Set the Query Converter Large Language Model
============================================

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

:ref:`Query Converter <rm-query-converter>` generates application code to
streamline migrating an application from its original database
into MongoDB. Query Converter is powered by generative AI. By default, it uses
the GPT-4o model, hosted on MongoDB's `Azure OpenAI
<https://azure.microsoft.com/en-us/products/ai-services/openai-service>`__
subscription. You can configure Query Converter to use a different Large
Language Model (LLM) by following these steps.


Before You Begin
----------------

- Review the list of :ref:`supported providers and models <rm-supported-llms>`.
- Configure your API service provider.
  This can include configuring access to the service, creating an API key or
  access credentials for Query Converter, or provisioning other resources.
  See your AI service provider's documentation for details.

Steps
-----

.. procedure::
   :style: normal

   .. step:: Stop Relational Migrator.

   .. step:: Open the configuration file.

      This file is located at:

      .. include:: /includes/fact-user-properties-location.rst

   .. step:: Configure Relational Migrator for your LLM.

      Add or set the following ``migrator.queryconversion.llm.options``. If 
      you're changing your LLM configuration, remove any that aren't used for 
      the new LLM.

      .. tabs::

         .. tab:: Azure OpenAI
            :tabid: llm-settings-azure-openai

            With `Azure OpenAI
            <https://azure.microsoft.com/en-us/products/ai-services/openai-service>`__,
            Query Converter supports the `GPT-4o
            <https://platform.openai.com/docs/models#gpt-4o>`__ and `GPT-4
            <https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4>`__
            models.

            **Example**

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: AzureOpenAI
               migrator.queryconversion.llm.options.apiKey: <API key>
               migrator.queryconversion.llm.options.apiVersion: 2024-10-21
               migrator.queryconversion.llm.options.deployment: myDeployment
               migrator.queryconversion.llm.options.baseUrl: https://my-test-endpoint.openai.azure.com/
               migrator.queryconversion.llm.options.model: gpt-4o

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``AzureOpenAI``

               * - ``migrator.queryconversion.llm.options.apiKey``
                 - Your Azure OpenAI API key.

               * - ``migrator.queryconversion.llm.options.apiVersion``
                 - The Azure OpenAI API version, in the format ``YYYY-MM-DD``.

               * - ``migrator.queryconversion.llm.options.deployment``
                 - The Azure OpenAI deployment name, found in the **Model
                   Deployments** page of the Azure portal.

               * - ``migrator.queryconversion.llm.options.baseUrl``
                 - The Azure OpenAI endpoint, found in the **Keys and
                   Endpoint** section in the Azure portal.

               * - ``migrator.queryconversion.llm.options.model``
                 - ``gpt-4`` or ``gpt-4o``

            For more information, see the `Azure OpenAI documentation <https://learn.microsoft.com/en-us/azure/ai-services/openai/>`__.



         .. tab:: OpenAI
            :tabid: llm-settings-openai

            With `OpenAI <https://platform.openai.com/docs/overview>`__, Query
            Converter supports the `GPT-4o
            <https://platform.openai.com/docs/models#gpt-4o>`__ and `GPT-4
            <https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4>`__
            models.

            **Example** 

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: OpenAI
               migrator.queryconversion.llm.options.apiKey: <API key>
               migrator.queryconversion.llm.options.baseUrl: https://api.openai.com/v1
               migrator.queryconversion.llm.options.model: gpt-4

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``OpenAI``

               * - ``migrator.queryconversion.llm.options.apiKey``
                 - Your OpenAI API key, generated in the `OpenAI dashboard <https://platform.openai.com/api-keys>`__.

               * - ``migrator.queryconversion.llm.options.baseUrl``
                 - ``https://api.openai.com/v1``

               * - ``migrator.queryconversion.llm.options.model``
                 - ``gpt-4`` or ``gpt-4o``

            For more information, see the `OpenAI documentation
            <https://platform.openai.com/docs/overview>`__.



         .. tab:: Amazon Bedrock
            :tabid: llm-settings-aws-bedrock

            With `Amazon Bedrock <https://aws.amazon.com/bedrock/>`__, Query Converter supports the `Claude 3.5 (Sonnet)
            <https://docs.anthropic.com/en/api/claude-on-amazon-bedrock>`__ and
            `Mistral Large <https://docs.mistral.ai/deployment/cloud/aws/>`__
            models.

            **Example**

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: AWSBedrock
               migrator.queryconversion.llm.options.awsAccessKeyId: AKIAIOSFODNN7EXAMPLE
               migrator.queryconversion.llm.options.awsSecretAccessKey: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
               migrator.queryconversion.llm.options.regionName: us-east-1
               migrator.queryconversion.llm.options.modelId: anthropic.claude-3-5-sonnet-20241022-v2:0

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``AWSBedrock``

               * - ``migrator.queryconversion.llm.options.awsAccessKeyId``
                 - The ID for an `AWS access key <https://docs.aws.amazon.com/kms/latest/developerguide/overview.html>`__
                   associated with an IAM account.

               * - ``migrator.queryconversion.llm.options.awsSecretAccessKey``
                 - The AWS access key for the account.

               * - ``migrator.queryconversion.llm.options.regionName``
                 - The `regional endpoint <https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints>`__ 
                   where the model is deployed.

               * - ``migrator.queryconversion.llm.options.modelId``
                 - ``anthropic.claude-3-5-sonnet-20241022-v2:0`` or ``mistral.mistral-large-2407-v1:0``

            For more information, see the `Amazon Bedrock documentation
            <https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html>`__,
            or the model-specific documentation from `Anthropic
            <https://docs.anthropic.com/en/api/claude-on-amazon-bedrock>`__ or
            `Mistral <https://docs.mistral.ai/deployment/cloud/aws/>`__. 


         .. tab:: GCP Vertex AI
            :tabid: llm-settings-gcp-vertex

            With `GCP Vertex AI <https://cloud.google.com/vertex-ai>`__, Query Converter supports the `Gemini 1.5 Pro
            <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`__
            model.

            **Example**

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: GCPVertex
               migrator.queryconversion.llm.options.apiKey:
               migrator.queryconversion.llm.options.model: gemini-1.5-pro-001

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``GCPVertex``

               * - ``migrator.queryconversion.llm.options.apiKey``
                 - Leave blank. Establish your `Application Default
                   Credentials
                   <https://cloud.google.com/docs/authentication/provide-credentials-adc>`__
                   with GCP through one of the other provided mechanisms.

               * - ``migrator.queryconversion.llm.options.model``
                 - ``gemini-1.5-pro-001`` or ``gemini-1.5-pro-002``

            For more information, see the `Google Vertex AI documentation
            <https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal>`__.



         .. tab:: Self-Managed
            :tabid: llm-settings-self-managed

            With self-managed local or Cloud deployments, Query Converter supports the `Llama 3.1 405B <https://www.llama.com/docs/getting_the_models>`__
            model.

            .. code-block:: javascript
               :copyable: true

               <WIP>

   
   .. step:: Save and close the file, and restart Relational Migrator.


Next Steps
----------

If you haven't already, :ref:`enable Query Converter <rm-enable-query-converter>`.